read.csv("../data/filledDatabase.csv") %>% clean_data2() %>% View()
clean_data2 = function(data){
data[!apply(data, 2, function(x) any(is.nan(x))),]
}
# load raw data files
read.csv("../data/filledDatabase.csv") %>% clean_data2() %>% View()
data <- read.csv("../data/filledDatabase.csv")
data[!apply(data, 2, function(x) any(is.nan(x))),]
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
View(data)
data$GroupCat[3] %>% is.nan*
()
data$GroupCat[3] %>% is.nan()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
data[apply(data, 2, function(x) any(!is.nan(x))),]
any(is.nan(data[3,]))
# load raw data files
read.csv("../data/filledDatabase.csv") %>% subset(!is.na()) %>% View()
# load raw data files
read.csv("../data/filledDatabase.csv") %>% na.omit()
# load raw data files
data <- read.csv("../data/filledDatabase.csv") %>% clean_data()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data)
table(data$GroupCat)
# clean data
data <- clean_data(data) %>% collapse_data()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
View(data)
data$X == data$Xprime
data$X == data$Xprime %>% sum()
sum(data$X == data$Xprime)
dim(data)
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
table(data$Z)
table(data$GroupCat)
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
View(data)
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
data <- read.csv("../data/filledDatabase.csv")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(-2:-9,-11:-13)]
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
names(data)
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
View(X)
str(X)
X = data[,-1]
str(X)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
Y = data$GroupCat
str(Y)
table(Y)
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data)
table(data$GroupCat)
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
Vie(X)
View(X)
View(Y)
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
summary(X)
is.na(X)
sum(is.na(X))
sum(is.nan(X))
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
model_lasso <- glmnet(x = X, y = Y, alpha = 1, family = "multinomial")
X = data[,-1]
Y = data$GroupCat
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
library(fastDummies)
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup")
Y = data$GroupCat %>% as.matrix()
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup))
Y = data$GroupCat %>% as.matrix()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
space_group <- data$SpaceGroup
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup))
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup)) %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
plot(model_ridge, xvar = "lambda", label = TRUE)
clean_data = function(data){
# remove duplicated rows
data = unique(data)
# remove missing values
Gurl = data
data[Gurl==-300] = NA
data = na.omit(data)
data$SpaceGroup = as.factor(data$SpaceGroup)
return(data)
}
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
library(fastDummies)
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup)) %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
clean_data = function(data){
# remove duplicated rows
data = unique(data)
# remove missing values
Gurl = data
data[Gurl==-300] = NA
data = na.omit(data)
data$SpaceGroup = as.character(data$SpaceGroup)
return(data)
}
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup)) %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
c("dog","cat") %>% class()
clean_data = function(data){
# remove duplicated rows
data = unique(data)
# remove missing values
Gurl = data
data[Gurl==-300] = NA
data = na.omit(data)
data$SpaceGroup = as.factor(as.character(data$SpaceGroup))
return(data)
}
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
library(fastDummies)
source("../scripts/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup)) %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
clean_data = function(data){
# remove duplicated rows
data = unique(data)
# remove missing values
Gurl = data
data[Gurl==-300] = NA
data = na.omit(data)
data$SpaceGroup = as.factor(as.character(data$SpaceGroup))
return(data)
}
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
View(data)
table(data$SpaceGroup)
space_group <- data$SpaceGroup
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
space_group <- data$SpaceGroup
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup)) %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
library(glmnet)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup)) %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
str(X)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% select(-c(SpaceGroup))
str(X)
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% dummy_cols(select_columns = "SpaceGroupNumber")
X = data[,-1] %>% dummy_cols(select_columns = "SpaceGroup") %>% fastDummies::dummy_cols(select_columns = "SpaceGroupNumber") %>% select(-c(SpaceGroup)) %>% as.matrix()
model_lasso <- glmnet(x = X, y = Y, alpha = 1, family = "multinomial")
plot(model_lasso, xvar = "lambda", label = TRUE)
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>%
get_coef(tuning_parameter = ridge_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Hexagonal, Others) %>%
plot_coef()
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>%
get_coef(tuning_parameter = ridge_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Others) %>%
plot_coef()
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>%
get_coef(tuning_parameter = ridge_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Others) %>%
plot_coef()
lasso_cv <- cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 5, type.measure = "deviance", family = "multinomial")
lasso_cv %>%
get_coef(tuning_parameter = lasso_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Others) %>%
plot_coef()
