lasso_cv %>% get_coef(tuning_parameter = lasso_cv$lambda.min) %>% plot_coef()
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X"))
data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
View(X)
View(Y)
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
collapse_data <- function(data){
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relabel(sort))
}
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
data <- clean_data(data)
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relabel(sort))
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relabel(GroupCat, sort))
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X"))
data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
plot(model_ridge, xvar = "lambda", label = TRUE)
model_lasso <- glmnet(x = X, y = Y, alpha = 1, family = "multinomial")
plot(model_lasso, xvar = "lambda", label = TRUE)
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min) %>% plot_coef()
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relabel(GroupCat, sort, "Others", after = Inf))
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relabel(GroupCat, "Others", after = Inf))
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relabel(GroupCat, "Others", after = Inf))
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
collapse_data <- function(data){
data %>%
mutate(GroupCat = fct_other(factor(GroupCat), keep = c(6,3,5), other_level = 'Others'),
GroupCat = recode(GroupCat, "3"="Cubic", "5"="Tilted", "6"="Hexagonal"),
GroupCat = fct_relevel(GroupCat, "Others", after = Inf))
}
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X"))
data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
plot(model_ridge, xvar = "lambda", label = TRUE)
model_lasso <- glmnet(x = X, y = Y, alpha = 1, family = "multinomial")
plot(model_lasso, xvar = "lambda", label = TRUE)
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min) %>% plot_coef()
lasso_cv <- cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 5, type.measure = "deviance", family = "multinomial")
lasso_cv %>% get_coef(tuning_parameter = lasso_cv$lambda.min) %>% plot_coef()
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X"))
data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
plot(model_ridge, xvar = "lambda", label = TRUE)
model_lasso <- glmnet(x = X, y = Y, alpha = 1, family = "multinomial")
plot(model_lasso, xvar = "lambda", label = TRUE)
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min) %>% plot_coef()
lasso_cv <- cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 5, type.measure = "deviance", family = "multinomial")
lasso_cv %>% get_coef(tuning_parameter = lasso_cv$lambda.min) %>% plot_coef()
library(caret)
elastic_cv <-
train(GroupCat ~., data = data, method = "glmnet",
trControl = trainControl("cv", number = 5),
tuneLength = 10
)
elastic_cv$finalModel %>% get_coef(tuning_parameter = elastic_cv$bestTune$lambda) %>% plot_coef()
tb_ridge = prediction_table(alpha = 0, lambda = ridge_cv$lambda.min)
tb_ridge$r %>% print_accurate_tb()
tb_ridge$t %>% highlight_tb_count()
tb_ridge$t %>% highlight_tb_percent()
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase111119NUMONLY.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X"))
data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
levels(data$GroupCat)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
plot(model_ridge, xvar = "lambda", label = TRUE)
model_lasso <- glmnet(x = X, y = Y, alpha = 1, family = "multinomial")
plot(model_lasso, xvar = "lambda", label = TRUE)
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min) %>% plot_coef()
ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min)
names(ridge_cv)
ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min)
t = ridge_cv %>% get_coef(tuning_parameter = ridge_cv$lambda.min)
names(t)
ridge_cv <- cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5, type.measure = "deviance", family = "multinomial")
ridge_cv %>%
get_coef(tuning_parameter = ridge_cv$lambda.min) %>%
select() %>% plot_coef()
ridge_cv %>%
get_coef(tuning_parameter = ridge_cv$lambda.min) %>%
select(feature, Cubic, Titled, Hexagonal, Others) %>%
plot_coef()
ridge_cv %>%
get_coef(tuning_parameter = ridge_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Hexagonal, Others) %>%
plot_coef()
lasso_cv <- cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 5, type.measure = "deviance", family = "multinomial")
lasso_cv %>%
get_coef(tuning_parameter = lasso_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Hexagonal, Others) %>%
plot_coef()
lasso_cv <- cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 5, type.measure = "deviance", family = "multinomial")
lasso_cv %>%
get_coef(tuning_parameter = lasso_cv$lambda.min) %>%
select(feature, Cubic, Tilted, Hexagonal, Others) %>%
plot_coef()
tb_ridge = prediction_table(alpha = 0, lambda = ridge_cv$lambda.min)
tb_ridge$r
tb_ridge$t
tb_ridge$r %>% print_accurate_tb()
tb_ridge$t
tb_ridge
tb_ridge
tb_ridge$t %>%
as.data.frame() %>%
arrange(desc(Freq))
tb_ridge = prediction_table(alpha = 0, lambda = ridge_cv$lambda.min)
tb_ridge$r %>% print_accurate_tb()
tb_ridge$t %>% highlight_tb_count()
tb_ridge$t %>% highlight_tb_percent()
tb_ridge$t %>%
as.data.frame() %>%
arrange(desc(Freq)) %>%
tb_ridge$t %>%
as.data.frame() %>%
arrange(desc(Freq)) %>%
table()
tb_ridge$t
200+380+570
knitr::opts_chunk$set(
fig.align = "center",
fig.pos = "H",
fig.width = 5,
fig.height = 3,
message = FALSE,
warning = FALSE,
external = TRUE,
echo = TRUE
)
library(tidyverse)
library(magrittr)
library(ggsci)
library(kableExtra)
source("../R script/functions.R")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X"))
data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
View(data)
data[apply(data, 2, function(x) any(is.nan(x))),]
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
data <- clean_data2(data)
clean_data2 = function(data){
data[apply(data, 2, function(x) any(is.nan(x))),]
}
data <- clean_data2(data)
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
apply(data, 2, function(x) any(is.nan(x)))
data[-apply(data, 2, function(x) any(is.nan(x))),]
clean_data2 = function(data){
data[-apply(data, 2, function(x) any(is.nan(x))),]
}
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
data <- clean_data2(data)
# load raw data files
read.csv("../data/filledDatabase.csv") %>% clean_data2() %>% View()
clean_data2 = function(data){
data[-apply(data, 2, function(x) any(is.nan(x))),]
}
# load raw data files
read.csv("../data/filledDatabase.csv") %>% clean_data2() %>% View()
clean_data2 = function(data){
data[!apply(data, 2, function(x) any(is.nan(x))),]
}
# load raw data files
read.csv("../data/filledDatabase.csv") %>% clean_data2() %>% View()
data <- read.csv("../data/filledDatabase.csv")
data[!apply(data, 2, function(x) any(is.nan(x))),]
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
View(data)
data$GroupCat[3] %>% is.nan*
()
data$GroupCat[3] %>% is.nan()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
data[apply(data, 2, function(x) any(!is.nan(x))),]
any(is.nan(data[3,]))
# load raw data files
read.csv("../data/filledDatabase.csv") %>% subset(!is.na()) %>% View()
# load raw data files
read.csv("../data/filledDatabase.csv") %>% na.omit()
# load raw data files
data <- read.csv("../data/filledDatabase.csv") %>% clean_data()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data)
table(data$GroupCat)
# clean data
data <- clean_data(data) %>% collapse_data()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
View(data)
data$X == data$Xprime
data$X == data$Xprime %>% sum()
sum(data$X == data$Xprime)
dim(data)
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
table(data$Z)
table(data$GroupCat)
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,c(-2:-13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
View(data)
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
data <- read.csv("../data/filledDatabase.csv")
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(-2:-9,-11:-13)]
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
names(data)
# load raw data files
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data) %>% collapse_data()
# separate compound and group_cate from the predictors
compound <- data$Compound
group_cat <- data$GroupCat
# create data constructed by first 13 PC's
data <- select(data, -c("Compound","X","Z"))
# data_pca <- get_pc_space(data[,-1], k = 13) %>% scale() %>% data.frame()
# split data into 5 folds for cross validation later
folds <- caret::createFolds(1:nrow(data), k = 5, list = TRUE, returnTrain = FALSE)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
View(X)
str(X)
X = data[,-1]
str(X)
library(glmnet)
X = data[,-1] %>% as.matrix()
Y = data$GroupCat %>% as.matrix()
model_ridge <- glmnet(x = X, y = Y, alpha = 0, family = "multinomial")
Y = data$GroupCat
str(Y)
table(Y)
data <- read.csv("../data/filledDatabase.csv")[,-c(2:9,11:13)]
# clean data
data <- clean_data(data)
table(data$GroupCat)
