}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
mean(Y==Y_pred)
### GBM on same folds
t = lapply(folds, function(id) {
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = gbm(GroupCat~., data = data.frame(X_train, GroupCat = Y_train),
shrinkage = 0.01, distribution = "multinomial",
n.trees = 3000, verbose = F, train.fraction = 1)
Y_pred = predict(model, n.trees = 3000,
newdata = as.data.frame(X_test),
type = "response") %>%
apply(., 1, which.max) %>%
recode(
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted"
)
table(factor(Y_pred, levels = levels(factor(data$GroupCat))),
factor(Y_test, levels = levels(factor(data$GroupCat))))
})
lapply(t, function(x) sum(diag(x))/sum(x)) %>% unlist()
Reduce("+",t) %>% as.matrix()
lapply(t, function(x) sum(diag(x))/sum(x)) %>% unlist() %>% print_accurate_tb()
subset2 <- data %>%
filter(X == "O") %>%
filter(GroupCat != "NCOT") %>%
droplevels()
X <- subset2[,-c(1:4)] %>% remove_identical_cal() %>% as.matrix()
Y <- subset2$GroupCat %>% droplevels() %>% as.matrix()
set.seed(2020)
folds <- createFolds(1:nrow(X), k = 5, list = TRUE, returnTrain = FALSE)
t = lapply(folds, function(id) {
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = gbm(GroupCat~., data = data.frame(X_train, GroupCat = Y_train),
shrinkage = 0.01, distribution = "multinomial",
n.trees = 3000, verbose = F, train.fraction = 1)
Y_pred = predict(model, n.trees = 3000,
newdata = as.data.frame(X_test),
type = "response") %>%
apply(., 1, which.max) %>%
recode(
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted"
)
table(factor(Y_pred, levels = levels(factor(data$GroupCat))),
factor(Y_test, levels = levels(factor(data$GroupCat))))
})
lapply(t, function(x) sum(diag(x))/sum(x)) %>% unlist() %>% print_accurate_tb()
Reduce("+",t) %>% as.matrix()
Reduce("+",t) %>% as.matrix() %>% highlight_tb_count()
Reduce("+",t) %>% as.matrix() %>% select(-NCOT) %>% highlight_tb_percent()
Reduce("+",t)  %>% select(-NCOT) %>% highlight_tb_percent()
Reduce("+",t) %>% as.matrix() %>% as.data.frame() %>% select(-NCOT) %>% highlight_tb_percent()
Reduce("+",t) %>% as.matrix() %>% as.data.frame()
Reduce("+",t) %>% as.matrix()
Reduce("+",t) %>% as.matrix()[,-5] %>% select(-NCOT) %>% highlight_tb_percent()
Reduce("+",t) %>% as.matrix()[,-5]
Reduce("+",t) %>% as.matrix() %>% .[,-5] %>% select(-NCOT) %>% highlight_tb_percent()
Reduce("+",t) %>% as.matrix() %>% .[,-5]
Reduce("+",t) %>% as.matrix() %>% .[,-5] %>% highlight_tb_percent()
Reduce("+",t) %>% as.matrix() %>% .[,-5] %>% highlight_tb_count()
Reduce("+",t) %>% as.matrix() %>% .[,-5] %>% highlight_tb_percent()
lapply(t, function(x) sum(diag(x))/sum(x)) %>% unlist() %>% print_accurate_tb()
Reduce("+",t) %>% as.matrix() %>% .[,-5] %>% highlight_tb_percent()
top3 <- c("ToleranceBVP", "IonizationPotentialofA", "CrystalRadiusofA")
Y_pred = Y
for(i in 1:length(folds)){
id = folds[[i]]
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = glmnet(x = X_train, y = Y_train, alpha = 1, family = "multinomial")
Y_pred[id] = predict(model, newx = X_test, type = "class", s = lasso_cv$lambda.min)
}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
mean(Y==Y_pred)
subset <- data %>% filter(X == "F")
table(subset$GroupCat) %>% sort(decreasing = TRUE)
X <- subset[,-c(1:4)] %>% remove_identical_cal() %>% as.matrix()
Y <- subset$GroupCat %>% droplevels() %>% as.matrix()
pca <- prcomp(X, scale = TRUE)
summary(pca)
X_PC <- pca$x[,1:17] %>% as.matrix()
PC_point <- data.frame(Compound = subset$Compound,
Cluster = as.character(subset$GroupCat),
X_PC)
PC <- pca$rotation %>%
as.data.frame() %>%
select(PC1,PC2,PC3) %>%
rownames_to_column("variable") %>%
mutate(tag = "end",
contribution = PC1^2 + PC2^2 + PC3^2)
PC[,2:4] <- PC[,2:4]*30
PC_initial <- PC %>% mutate(tag = "start")
PC_initial[,2:4] = 0
PC_arrow <- bind_rows(PC, PC_initial)
PC_arrow %>%
group_by(variable) %>%
plot_ly() %>%
add_trace(
x = ~PC1,
y = ~PC2,
z = ~PC3,
color = ~contribution,
text = ~variable,
type = 'scatter3d', mode = 'lines', opacity = 1,
line = list(width = 6, reverscale = FALSE)
) %>%
add_markers(
data = PC_point,
x = ~PC1,
y = ~PC2,
z = ~PC3,
color = ~Cluster,
colors = "Dark2",
text = ~Compound,
opacity = 0.9)
#### -------------   step 1: ridge   ------------- ####
subset2 <- data %>%
filter(X == "F") %>%
filter(!(GroupCat %in% c("LiNb03","NCOT"))) %>%
droplevels()
X <- subset2[,-c(1:4)] %>% remove_identical_cal() %>% as.matrix()
Y <- subset2$GroupCat %>% droplevels() %>% as.matrix()
dim(subset)
#### -------------   step 1: ridge   ------------- ####
subset2 <- data %>%
filter(X == "F") %>%
filter(!(GroupCat %in% c("LiNb03","NCOT"))) %>%
droplevels()
X <- subset2[,-c(1:4)] %>% remove_identical_cal() %>% as.matrix()
Y <- subset2$GroupCat %>% droplevels() %>% as.matrix()
set.seed(2020)
folds <- caret::createFolds(1:nrow(X), k = 5, list = TRUE, returnTrain = FALSE)
ridge_cv = cv.glmnet(x = X, y = Y, alpha = 0, nfolds = 5,
type.measure = "deviance", family = "multinomial")
tb_ridge = prediction_table(alpha = 0, lambda = ridge_cv$lambda.min)
tb_ridge$r %>% print_accurate_tb()
#### -------------   step 2: lasso   ------------- ####
lasso_cv = cv.glmnet(x = X, y = Y, alpha = 1, nfolds = 5,
type.measure = "deviance", family = "multinomial")
tb_lasso = prediction_table(alpha = 1, lambda = lasso_cv$lambda.min)
tb_lasso$r %>% print_accurate_tb()
#### -------------   step 3: elastic net   ------------- ####
elastic_cv <-
train(GroupCat ~., data = data.frame(X, GroupCat = Y), method = "glmnet",
trControl = trainControl("cv", number = 5),
tuneLength = 10)
tb_elastic = prediction_table(alpha = elastic_cv$bestTune[[1]],
lambda = elastic_cv$bestTune[[2]])
tb_elastic$r %>% print_accurate_tb()
tb_elastic$t[,-(4:5)] %>% highlight_tb_count()
#### -------------   step 4: GBM   ------------- ####
gbm_cv <- gbm(GroupCat~., data = subset2[,-c(1:3)],
shrinkage = 0.01, distribution = "multinomial",
cv.folds = 5, n.trees = 3000, verbose = F)
best.iter = gbm.perf(gbm_cv, method="cv")
summary(gbm_cv) %>% View()
#### -------------   step 4: GBM   ------------- ####
gbm_cv <- gbm(GroupCat~., data = subset2[,-c(1:3)],
shrinkage = 0.01, distribution = "multinomial",
cv.folds = 5, n.trees = 3000, verbose = F)
best.iter = gbm.perf(gbm_cv, method="cv")
summary(gbm_cv) %>% View()
t = lapply(folds, function(id) {
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = gbm(GroupCat~., data = data.frame(X_train, GroupCat = Y_train),
shrinkage = 0.01, distribution = "multinomial",
n.trees = 3000, verbose = F, train.fraction = 1)
Y_pred = predict(model, n.trees = 3000,
newdata = as.data.frame(X_test),
type = "response") %>%
apply(., 1, which.max) %>%
recode(
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted"
)
table(factor(Y_pred, levels = levels(factor(data$GroupCat))),
factor(Y_test, levels = levels(factor(data$GroupCat))))
})
lapply(t, function(x) sum(diag(x))/sum(x)) %>% unlist() %>% print_accurate_tb()
Reduce("+",t) %>% as.matrix() %>% .[,-5] %>% highlight_tb_count()
Reduce("+",t) %>% as.matrix() %>% .[,-(4:5)] %>% highlight_tb_count()
Reduce("+",t) %>% as.matrix() %>% .[,-(4:5)] %>% highlight_tb_percent()
Reduce("+",t) %>% as.matrix() %>% .[,-(4:5)] %>% highlight_tb_count()
Reduce("+",t) %>% as.matrix() %>% .[,-(4:5)] %>% highlight_tb_percent()
tb_ridge$t[,-(4:5)] %>% highlight_tb_percent()
tb_lasso$t[,-(4:5)] %>% highlight_tb_count()
tb_lasso$t[,-(4:5)] %>% highlight_tb_percent()
#### -------------   step 3: elastic net   ------------- ####
elastic_cv <-
train(GroupCat ~., data = data.frame(X, GroupCat = Y), method = "glmnet",
trControl = trainControl("cv", number = 5),
tuneLength = 10)
tb_elastic = prediction_table(alpha = elastic_cv$bestTune[[1]],
lambda = elastic_cv$bestTune[[2]])
tb_elastic$r %>% print_accurate_tb()
tb_elastic$t[,-(4:5)] %>% highlight_tb_count()
tb_elastic$t[,-(4:5)] %>% highlight_tb_percent()
elastic_cv$finalModel %>%
get_coef(tuning_parameter = elastic_cv$bestTune$lambda) %>%
View()
lapply(t, function(x) sum(diag(x))/sum(x)) %>% unlist() %>% print_accurate_tb()
Reduce("+",t) %>% as.matrix() %>% .[,-(4:5)] %>% highlight_tb_percent()
Y_pred = Y
for(i in 1:length(folds)){
id = folds[[i]]
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = glmnet(x = X_train, y = Y_train, family = "multinomial",
alpha = elastic_cv$bestTune[[1]])
Y_pred[id] = predict(model, newx = X_test, type = "class",
s = elastic_cv$bestTune[[2]])
}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
mean(Y==Y_pred)
summary(gbm_cv) %>% View()
#### -------------   step 4: GBM   ------------- ####
gbm_cv <- gbm(GroupCat~., data = subset2[,-c(1:3)],
shrinkage = 0.01, distribution = "multinomial",
cv.folds = 5, n.trees = 3000, verbose = F)
best.iter = gbm.perf(gbm_cv, method="cv")
summary(gbm_cv) %>% View()
top3 <- c("ToleranceBVP", "DensityatSpecofA", "CrystalRadiusofBprime")
Y_pred = Y
for(i in 1:length(folds)){
id = folds[[i]]
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = glmnet(x = X_train, y = Y_train, family = "multinomial",
alpha = elastic_cv$bestTune[[1]])
Y_pred[id] = predict(model, newx = X_test, type = "class",
s = elastic_cv$bestTune[[2]])
}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~IonizationPotentialofA,
z = ~CrystalRadiusofA,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
Y_pred = Y
for(i in 1:length(folds)){
id = folds[[i]]
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = glmnet(x = X_train, y = Y_train, family = "multinomial",
alpha = elastic_cv$bestTune[[1]])
Y_pred[id] = predict(model, newx = X_test, type = "class",
s = elastic_cv$bestTune[[2]])
}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~DensityatSpecofA,
z = ~CrystalRadiusofBprime,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~DensityatSpecofA,
z = ~CrystalRadiusofBprime,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
mean(Y==Y_pred)
Y_pred = Y
for(i in 1:length(folds)){
id = folds[[i]]
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = gbm(GroupCat~., data = data.frame(X_train, GroupCat = Y_train),
shrinkage = 0.01, distribution = "multinomial",
n.trees = 3000, verbose = F, train.fraction = 1)
Y_pred[id] = predict(model, n.trees = 3000,
newdata = as.data.frame(X_test),
type = "response") %>%
apply(., 1, which.max)
}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
mean(Y==Y_pred)
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~DensityatSpecofA,
z = ~CrystalRadiusofBprime,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~DensityatSpecofA,
z = ~CrystalRadiusofBprime,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
Y_pred = Y
for(i in 1:length(folds)){
id = folds[[i]]
X_test = X[id,]; X_train = X[-id,]
Y_test = Y[id]; Y_train = Y[-id]
model = glmnet(x = X_train, y = Y_train, family = "multinomial", alpha = 1)
Y_pred[id] = predict(model, newx = X_test, type = "class",
s =  lasso_cv$lambda.min)
}
Y_pred = recode(Y_pred,
"1" = "Cubic",
"2" = "Hexagonal",
"3" = "LiNb03",
"4" = "Tilted")
df_plot <-
data.frame(
Compound = subset2$Compound,
Cluster = as.character(subset2$GroupCat),
X[,top3],
tag = ifelse(Y_pred == Y, 'correct', 'wrong')
)
plot_ly() %>%
add_trace(
data = df_plot %>% filter(tag == 'correct'),
x = ~ToleranceBVP,
y = ~DensityatSpecofA,
z = ~CrystalRadiusofBprime,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
opacity = 0.8
) %>%
add_trace(
data = df_plot %>% filter(tag == 'wrong'),
x = ~ToleranceBVP,
y = ~DensityatSpecofA,
z = ~CrystalRadiusofBprime,
color = ~Cluster,
text = ~Compound,
type = 'scatter3d', mode = 'markers',
marker = list(line = list(color = "red", width = 2, opacity = 0.5)),
opacity = 0.8
)
mean(Y==Y_pred)
